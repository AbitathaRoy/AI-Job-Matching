as.numeric(diffs) / 52
}, resume_data$start_dates_parsed, resume_data$end_dates_parsed, SIMPLIFY = FALSE)
# Testing
class(resume_data$start_dates_parsed[[2]])
head(resume_data$start_dates_parsed)
head(Map(function(s, e, x) list(start = s, end = e, experience = x),
resume_data$start_dates_parsed,
resume_data$end_dates_parsed,
resume_data$experience_years), 5)
# Calculating total experience years
resume_data$total_experience_years <- sapply(resume_data$experience_years, function(x) {
if (all(is.na(x))) {
return(NA_real_)
} else {
return(sum(x, na.rm = TRUE))
}
})    # In our simplified case, while comparing years and stuff, we will consider the total experience gained till date
# Not the number of years in xyz role or abc field or things like that
# --- Education Level Mapping ---
head(resume_data$degree_name, 15)
# Converting data to lists
parse_degrees <- function(degree_str) {
# Remove brackets and split by commas
degrees <- gsub("\\[|\\]|'", "", degree_str)  # remove [ ] and '
degrees_split <- strsplit(degrees, ",")[[1]]
# Trim whitespace
degrees_trimmed <- trimws(degrees_split)
return(degrees_trimmed)
}
resume_data$degree_name_parsed <- lapply(resume_data$degree_name, parse_degrees)
head(resume_data$degree_name_parsed, 15)
# Define keyword lists for each academic level
below_class_x <- c("below class x", "none", "n/a", "select one", "skills", "course", "general courses", "seminar", "esol program", "kcpe", "correspondence/distance learning", "attending", "minor", "course revisions")
class_x <- c("class x", "x", "high school diploma", "ged", "grade 12", "school certificate", "kcse")
class_xii <- c("class xii", "xii", "a level", "certification", "certificate", "diploma", "technical diploma", "general diploma", "certificate of completion", "lean certification", "six sigma", "epa certification", "aws brazing", "poke-a-yoke", "neec building", "applied industrial ergonomics", "shipboard firefighting", "waste heat boilers", "class facilitator", "food handler", "project management graduate certificate", "business certification", "certified professional coach", "cacc certification", "pharmacy technician", "acca ii", "testing computer software", "principles of management", "association of business executive", "engineering common core", "engineering mechanical", "engineering electrical", "gas turbine mechanical/electrical", "shipbd gage cal", "machinery control system", "marine maintenance", "waste heat boilers")
ug <- c("b.tech", "b.sc", "b.a", "b.com", "b.e", "b.s", "b.b.a", "b.c.a", "bachelor", "bs", "ba", "be", "bba", "bca", "btech", "associate", "a.a", "a.s", "a.a.s", "honours bachelor", "integrated b.tech", "integrated b.e.", "bsc", "honors", "international business", "business development", "executive management")
pg <- c("m.tech", "m.sc", "m.a", "m.com", "m.b.a", "m.s", "m.e", "m.eng", "master", "msc", "ms", "mba", "mca", "post graduation", "pg diploma", "graduate certificate", "executive mba", "masters", "integrated m.tech", "integrated m.e.", "mbm", "mcom")
phd <- c("phd", "ph.d", "doctor of philosophy", "phd candidate", "d.b.a")
# Function to determine academic level
assign_academic_level <- function(degree_string) {
# Convert degree string to lowercase for case-insensitive matching
degree_string <- tolower(degree_string)
# Check lists in descending order to assign highest level
if (any(sapply(phd, function(x) grepl(x, degree_string)))) {
return(6)
} else if (any(sapply(pg, function(x) grepl(x, degree_string)))) {
return(5)
} else if (any(sapply(ug, function(x) grepl(x, degree_string)))) {
return(4)
} else if (any(sapply(class_xii, function(x) grepl(x, degree_string)))) {
return(3)
} else if (any(sapply(class_x, function(x) grepl(x, degree_string)))) {
return(2)
} else if (any(sapply(below_class_x, function(x) grepl(x, degree_string)))) {
return(1)
} else {
return(1) # Default to Below Class X for unmatched entries
}
}
# Apply the function to create the new column
resume_data$academic_level <- sapply(resume_data$degree_name_parsed, function(degree_vec) {
degree_string <- paste(degree_vec, collapse = " ")
assign_academic_level(degree_string)
})
head(resume_data$academic_level)
# --- Data Filtering ---
# Drop rows where all experience values are NA and where academic_level is NA
# Step 1: Identify which rows have all NAs in experience_years
# all_exp_na <- sapply(resume_data$experience_years, function(x) all(is.na(x)))
# Step 2: Subset the dataframe manually (using indexing)
# resume_data <- resume_data[!all_exp_na & !is.na(resume_data$academic_level), ]
# Drop rows where even one experience value is NA or where academic level is NA
library(tidyr)
resume_data <- resume_data %>%
drop_na(experience_years, academic_level)
# Checking if it worked. Should return 0.
# sum(sapply(resume_data$experience_years, function(x) all(is.na(x))))
# sum(is.na(resume_data$academic_level))
sum(is.na(resume_data$experience_years))
sum(is.na(resume_data$academic_level))
# --- Educational Requirements ---
assign_required_academic_level <- function(degree_string) {
# Convert degree string to lowercase for case-insensitive matching
degree_string <- tolower(degree_string)
# Check lists in ascending order to assign lowest level
if (any(sapply(below_class_x, function(x) grepl(x, degree_string)))) {
return(1)
} else if (any(sapply(class_x, function(x) grepl(x, degree_string)))) {
return(2)
} else if (any(sapply(class_xii, function(x) grepl(x, degree_string)))) {
return(3)
} else if (any(sapply(ug, function(x) grepl(x, degree_string)))) {
return(4)
} else if (any(sapply(pg, function(x) grepl(x, degree_string)))) {
return(5)
} else if (any(sapply(phd, function(x) grepl(x, degree_string)))) {
return(6)
} else {
return(1) # Default to Below Class X for unmatched entries
}
}
resume_data$required_academic_level <- sapply(resume_data$educationaL_requirements, function(degree_vec) {
degree_string <- paste(degree_vec, collapse = " ")
assign_required_academic_level(degree_string)
})
# --- Required Experience Years ---
# Renaming (well, not exactly)
resume_data$required_experience <- resume_data$experiencere_requirement
unique(resume_data$required_experience)
# Parsing and storing required experience as a vector
parse_experience_range <- function(text) {
text <- tolower(text)
if (grepl("at least", text)) {
num <- as.numeric(gsub("[^0-9]", "", text))
return(c(num, 100))
} else if (grepl("to", text)) {
bounds <- as.numeric(unlist(regmatches(text, gregexpr("[0-9]+", text))))
return(c(bounds[1], bounds[2]))
} else if (grepl("at most", text)) {
num <- as.numeric(gsub("[^0-9]", "", text))
return(c(0, num))
} else {
return(NA)  # For empty or unrecognized patterns
}
}
resume_data$required_experience_range <- lapply(resume_data$required_experience, function(exp_str) {
parse_experience_range(exp_str)
})
# Drop ineligible candidates (based on academic level and experience)
ranges <- resume_data$required_experience_range
experiences <- resume_data$total_experience_years
# Apply logic element-wise
valid_rows <- mapply(function(range, exp) {
if (is.null(range) || length(range) == 0 || all(is.na(range))) {
return(TRUE)  # Keep rows with NULL or empty `range` or all NA's
}
# Ensure that 'range' is a vector with exactly two values
if (length(range) != 2 || any(is.na(range)) || is.na(exp)) {
return(FALSE)  # Filter rows with invalid range or experience NA
}
# Check if the experience falls within the specified range
exp >= range[1] && exp <= range[2]
}, ranges, experiences)
# Filter the data based on the valid rows and academic level condition
resume_data <- resume_data[valid_rows & resume_data$academic_level >= resume_data$required_academic_level, ]
# --- Markov Chain Modeling for Career Transitions ---
# Assign candidate IDs
resume_data$candidate_id <- seq_len(nrow(resume_data))
# Parsed job positions held into vectors
parse_positions <- function(pos_string) {
if (is.na(pos_string)) return(NA)
# Remove square brackets and single/double quotes
cleaned <- gsub("\\[|\\]|'", "", pos_string)
# Split by comma
positions <- unlist(strsplit(cleaned, ","))
# Trim whitespace
positions <- trimws(positions)
return(positions)
}
resume_data$positions_parsed <- lapply(resume_data$positions, parse_positions)
library(dplyr)
library(tidyr)
library(purrr)
# Diagnostic: Check vector lengths for mismatches
resume_data <- resume_data %>%
mutate(
pos_length = map_int(positions_parsed, length),
start_length = map_int(start_dates_parsed, length),
end_length = map_int(end_dates_parsed, length),
length_mismatch = pos_length != start_length | pos_length != end_length
)
# Print rows with mismatched lengths for review
mismatch_rows <- resume_data %>%
filter(length_mismatch) %>%
select(candidate_id, pos_length, start_length, end_length, positions_parsed, start_dates_parsed, end_dates_parsed)
print("Rows with mismatched vector lengths:")
print(mismatch_rows)
# Function to pad vectors to the same length
pad_vectors <- function(pos, start, end) {
max_len <- max(length(pos), length(start), length(end))
list(
positions = c(pos, rep(NA, max_len - length(pos))),
start_dates = c(start, rep(NA, max_len - length(start))),
end_dates = c(end, rep(NA, max_len - length(end)))
)
}
# Prepare data by padding vectors
resume_data_padded <- resume_data %>%
mutate(
padded = pmap(list(positions_parsed, start_dates_parsed, end_dates_parsed), pad_vectors),
positions_parsed = map(padded, "positions"),
start_dates_parsed = map(padded, "start_dates"),
end_dates_parsed = map(padded, "end_dates")
) %>%
select(-padded)
# Create the transitions data frame
transitions <- resume_data_padded %>%
# Select relevant columns
select(candidate_id, positions_parsed, start_dates_parsed, end_dates_parsed) %>%
# Filter out rows with empty positions_parsed
filter(map_int(positions_parsed, length) > 0) %>%
# Unnest the vector columns into rows
unnest(cols = c(positions_parsed, start_dates_parsed, end_dates_parsed)) %>%
# Group by candidate_id to process each candidate's job history
group_by(candidate_id) %>%
# Arrange by reverse index to process from earliest to latest (since vectors are most recent first)
arrange(desc(row_number()), .by_group = TRUE) %>%
# Create current_position and next_position
mutate(
current_position = positions_parsed,
next_position = lead(positions_parsed)
) %>%
# Select final columns and rename dates
select(
candidate_id,
current_position,
next_position,
start_date = start_dates_parsed,
end_date = end_dates_parsed
) %>%
ungroup() %>%
# Remove rows with NA in current_position
filter(!is.na(current_position))
# -- MARKOV CHAIN --
library(dplyr)
library(markovchain)
# Prepare transitions for Markov chain
# Step 1: Filter out NA and invalid titles
valid_transitions <- transitions %>%
filter(
!is.na(current_position) &
!is.na(next_position) &
!current_position %in% c("N/A", "None") &
!next_position %in% c("N/A", "None")
)
# Step 2: Get common roles (roles in both current and next positions)
common_roles <- intersect(
unique(valid_transitions$current_position),
unique(valid_transitions$next_position)
)
# Step 3: Filter transitions to only common roles
valid_transitions <- valid_transitions %>%
filter(
current_position %in% common_roles &
next_position %in% common_roles
) %>%
select(current_position, next_position)
# Diagnostic: Check number of unique roles
cat("Number of common roles used:", length(common_roles), "\n")
cat("Unique roles in current_position:", length(unique(valid_transitions$current_position)), "\n")
cat("Unique roles in next_position:", length(unique(valid_transitions$next_position)), "\n")
# Step 4 (fixed): Create a complete square transition matrix
all_roles <- union(valid_transitions$current_position, valid_transitions$next_position)
trans_matrix <- table(
factor(valid_transitions$current_position, levels = all_roles),
factor(valid_transitions$next_position, levels = all_roles)
)
# Step 5 (force correct class): Convert to numeric matrix row-wise
prob_matrix <- prop.table(trans_matrix, 1)
prob_matrix <- matrix(as.numeric(prob_matrix),
nrow = nrow(trans_matrix),
dimnames = dimnames(trans_matrix))
class(prob_matrix)
# Fix numerical imprecision — re-normalize rows strictly
row_sums <- rowSums(prob_matrix)
prob_matrix <- sweep(prob_matrix, 1, row_sums, FUN = "/")
summary(rowSums(prob_matrix))  # Should all be 1
# Replace NaN (from zero rows) with 0
prob_matrix[is.nan(prob_matrix)] <- 0
summary(rowSums(prob_matrix))  # Should all be 1
# Step 6: Now the matrix is square (safe to proceed)
cat("Final square probability matrix dimensions:", dim(prob_matrix), "\n")
# - Fixing Errors with Assumptions -
# Step 7: Identify roles with zero transitions and handle them by assigning self-transition probability
# We will loop through each row of the transition matrix, checking for rows that sum to zero.
# If any row sums to zero (i.e., no one has transitioned out of that role), we will assign the
# transition probability for the self-transition (i.e., from the role to itself) to 1.
# Loop through each row of the probability matrix
for (i in 1:nrow(prob_matrix)) {
# Check if the sum of the row is zero (i.e., no one transitioned out of the role)
if (sum(prob_matrix[i, ]) == 0) {
# Assign the self-transition probability (current position to itself) to 1
prob_matrix[i, i] <- 1
}
}
# Check if the row sums are now all 1, as they should be for a valid Markov Chain transition matrix
cat("Row sums after fixing zero rows:\n")
summary(rowSums(prob_matrix))  # Should all be 1 after this step
# Step 8: Proceed with creating the Markov Chain object
# After ensuring the transition matrix is valid (all rows sum to 1), we can safely create the Markov chain
mc <- new("markovchain", transitionMatrix = prob_matrix)
# Final check
cat("Markov Chain successfully created.\n")
summary(mc)
# Optional: View sample of transition matrix
cat("\nSample of Transition Probability Matrix (first 5 roles):\n")
print(prob_matrix[1:5, 1:5])
# -- Analytics with Markov Chains --
# 1 - The top 10 and bottom 10 lucrative positions -
total_incoming_prob <- colSums(prob_matrix)
lucrative_jobs <- sort(total_incoming_prob, decreasing = TRUE)
cat("Most lucrative jobs:\n")
print(lucrative_jobs[1:10])  # Top 10 lucrative jobs
cat("\nLeast lucrative jobs:\n")
print(lucrative_jobs[(length(lucrative_jobs)-9):length(lucrative_jobs)])  # Bottom 10 lucrative jobs
# 2 - Job Stability - Self Transitions -
# Identify the jobs with the highest and lowest self-transition probabilities
highest_self_transitions <- sort(self_transition_prob, decreasing = TRUE)
total_incoming_prob <- colSums(prob_matrix)
total_incoming_prob <- colSums(prob_matrix)
lucrative_jobs <- sort(total_incoming_prob, decreasing = TRUE)
cat("Most lucrative jobs:\n")
print(lucrative_jobs[1:10])  # Top 10 lucrative jobs
cat("\nLeast lucrative jobs:\n")
print(lucrative_jobs[(length(lucrative_jobs)-9):length(lucrative_jobs)])  # Bottom 10 lucrative jobs
temp <- 20
print(lucrative_jobs[1:temp])  # Top temp lucrative jobs
print(lucrative_jobs[(length(lucrative_jobs)-(temp-1)):length(lucrative_jobs)])  # Bottom 10 lucrative jobs
self_transition_prob <- function(prob_matrix) {
# Extract the diagonal elements (self-transition probabilities)
diag_probs <- diag(prob_matrix)
# Get row and column names (labels)
row_labels <- rownames(prob_matrix)
col_labels <- colnames(prob_matrix)
names(diag_probs) <- row_labels
return(diag_probs)
}
# Identify the jobs with the highest and lowest self-transition probabilities
highest_self_transitions <- sort(self_transition_prob, decreasing = TRUE)
lowest_self_transitions <- sort(self_transition_prob, decreasing = FALSE)
# Identify the jobs with the highest and lowest self-transition probabilities
temp <- 10    # how many to show?
highest_self_transitions <- head(sort(self_transitions, decreasing = TRUE), n = temp)
self_transition_prob <- function(prob_matrix) {
# Extract the diagonal elements (self-transition probabilities)
diag_probs <- diag(prob_matrix)
# Get row and column names (labels)
row_labels <- rownames(prob_matrix)
col_labels <- colnames(prob_matrix)
names(diag_probs) <- row_labels
return(diag_probs)
}
# Calculate the self-transition probabilities
self_transitions <- self_transition_prob(my_prob_matrix)
# Calculate the self-transition probabilities
self_transitions <- self_transition_prob(prob_matrix)
# Identify the jobs with the highest and lowest self-transition probabilities
temp <- 10    # how many to show?
highest_self_transitions <- head(sort(self_transitions, decreasing = TRUE), n = temp)
lowest_self_transitions <- head(sort(self_transitions, decreasing = FALSE), n = temp)
# Print the results
cat("Self-Transition Probabilities:\n")
print(self_transitions)
cat("\nHighest Self-Transition Probabilities:\n")
print(highest_self_transitions)
cat("\nLowest Self-Transition Probabilities:\n")
print(lowest_self_transitions)
# Example: Transition probability from "Senior Accountant" to "Tax Analyst"
transition_prob <- prob_matrix["Senior Accountant", "Tax Analyst"]
print(transition_prob)
# Calculate steady-state distribution (using the power method or linear algebra)
steady_state <- rep(1, ncol(prob_matrix))  # Initial guess (uniform distribution)
steady_state <- steady_state %*% prob_matrix  # Multiply by transition matrix
steady_state <- steady_state / sum(steady_state)  # Normalize to sum to 1
print(steady_state)
library(ggplot2)
library(reshape2)
# Melt the matrix for visualization
prob_matrix_melted <- melt(prob_matrix)
# Create the heatmap
ggplot(prob_matrix_melted, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
xlab("From Job") +
ylab("To Job") +
ggtitle("Transition Probability Matrix Heatmap")
library(igraph)
# Create an igraph object from the transition matrix
graph <- graph_from_adjacency_matrix(prob_matrix, weighted = TRUE, mode = "directed")
# Plot the network
plot(graph, vertex.size = 5, vertex.label.cex = 0.7, edge.arrow.size = 0.5)
dist_matrix <- dist(prob_matrix)
hc <- hclust(dist_matrix)
# Plot the dendrogram
plot(hc)
simulate_career <- function(start_role, steps) {
current_state <- start_role
for (i in 1:steps) {
current_state <- sample(1:ncol(prob_matrix), 1, prob = prob_matrix[current_state, ])
print(rownames(prob_matrix)[current_state])
}
}
simulate_career("Software Engineer", 5)  # Simulate from "X" for n steps
# --- Z-score Ranking --- [FLAGGED]
library(dplyr)
library(stringr)
library(purrr)
# Define parser for Python-style skill lists
parse_list <- function(skill_str) {
skill_str %>%
str_remove_all("\\[|\\]|'") %>%     # remove square brackets and single quotes
str_split(",\\s*") %>%              # split by comma and optional spaces
unlist() %>%
str_trim() %>%
discard(~ .x == "")                 # remove empty strings
}
resume_data <- resume_data %>%
mutate(
skills_parsed = map(skills, parse_list),
num_skills = map_int(skills_parsed, length),
composite_score = 0.4 * num_skills +
0.3 * total_experience_years +
0.3 * academic_level,
z_score = as.numeric(scale(composite_score))
) %>%
arrange(desc(z_score))
# Set n for top candidates to display
n <- 10  # Change as needed
# Filter transitions where next_position is NA
filtered_transitions <- transitions %>%
filter(is.na(next_position))
# Join filtered transitions with resume_data on candidate_id
top_candidates <- resume_data %>%
filter(candidate_id %in% filtered_transitions$candidate_id) %>%
left_join(filtered_transitions, by = "candidate_id") %>%  # Join to get current_position
arrange(desc(z_score)) %>%
slice_head(n = n) %>%
select(candidate_id, current_position, z_score)  # Display relevant columns
# Print top candidates
print(top_candidates)
# --- Estimating Hiring Probability using Bayes Theorem ---
# Define the function to calculate hiring probability
calculate_hiring_probability <- function(experience_years, academic_level) {
# Mock conditional probabilities (based on assumptions or historical data if available)
p_hired <- 0.5  # Prior probability of getting hired
# Conditional probability of experience given hired
p_exp_given_hired <- ifelse(experience_years >= 5, 0.8,
ifelse(experience_years >= 2, 0.6, 0.3))
# Conditional probability of education given hired
p_edu_given_hired <- ifelse(academic_level >= 5, 0.9,
ifelse(academic_level >= 4, 0.7,
ifelse(academic_level >= 3, 0.5, 0.2)))
# Naive Bayes formula: P(H|E) ∝ P(E|H) * P(H)
numerator <- p_exp_given_hired * p_edu_given_hired * p_hired
denominator <- numerator + ((1 - p_exp_given_hired) * (1 - p_edu_given_hired) * (1 - p_hired))
hiring_probability <- numerator / denominator
return(hiring_probability)
}
# Apply the function to the cleaned resume data
resume_data$hiring_probability <- mapply(
calculate_hiring_probability,
resume_data$total_experience_years,
resume_data$academic_level
)
# Display hiring probability with relevant columns
print(resume_data[, c("total_experience_years", "academic_level", "hiring_probability")])
# --- Data Export ---
# Export the final ranked data to an RDS file
saveRDS(resume_data, ".\\resume_ranking_data.rds")
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)
# Fix list columns by unnesting or extracting dates
transitions <- transitions %>%
mutate(
start_date = map(start_date, ~ as_date(.x[[1]])),
end_date = map(end_date, ~ as_date(.x[[1]]))
) %>%
unnest(cols = c(start_date, end_date), keep_empty = TRUE)
# 1. Check column names and data types
cat("Checking table structure (columns and their types):\n")
str(transitions)
# 2. Check for missing values
cat("\nCounting empty (missing) values in each column:\n")
colSums(is.na(transitions))
# 3. Verify next_position is NA for the most recent role per candidate
recent_roles <- transitions %>%
group_by(candidate_id) %>%
filter(start_date == max(start_date, na.rm = TRUE)) %>%
summarise(has_na_next = is.na(next_position))
cat("\nChecking if the latest job for each candidate has no 'next job' (should be empty):\n")
recent_roles %>%
filter(!has_na_next) %>%
print(row.names = FALSE)
# 4. Check chronological order (start_date increasing within candidate_id)
chronology_check <- transitions %>%
group_by(candidate_id) %>%
arrange(start_date) %>%
mutate(is_ordered = start_date <= lead(start_date, default = as_date(Inf))) %>%
summarise(all_ordered = all(is_ordered, na.rm = TRUE)) %>%
filter(!all_ordered)
cat("\nChecking if jobs are listed in time order (oldest to newest):\n")
chronology_check %>%
print(row.names = FALSE)
# 5. Sample transitions for a few candidates (e.g., 3 candidates)
cat("\nShowing job history for 3 random candidates:\n")
sample_candidates <- transitions %>%
distinct(candidate_id) %>%
slice_head(n = 3) %>%
pull(candidate_id)
transitions %>%
filter(candidate_id %in% sample_candidates) %>%
arrange(candidate_id, start_date) %>%
print(n = Inf)
# 6. Summarize transitions per candidate
cat("\nSummary of how many job changes each candidate has:\n")
transitions %>%
group_by(candidate_id) %>%
summarise(num_transitions = n()) %>%
summary()
